{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import json,requests,pandas,time and csv\n",
    "import json\n",
    "import requests\n",
    "import pandas \n",
    "import time\n",
    "import csv\n",
    "#Reading csv file  \n",
    "result= pandas.read_csv(\"md5.csv\") \n",
    "#Writing the dataset.csv file \n",
    "with open('test.csv', mode='a') as datasetfile:\n",
    "    dataset_writer = csv.writer(datasetfile,delimiter='|',\n",
    "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    dataset_writer.writerow(['Name', 'md5', 'Machine', 'SectionsMeanEntropy',\n",
    "       'SectionsMinEntropy', 'SectionsMaxEntropy', 'SectionsMeanRawsize',\n",
    "       'SectionsMinRawsize', 'SectionMaxRawsize', 'SectionsMeanVirtualsize',\n",
    "       'SectionsMinVirtualsize', 'SectionMaxVirtualsize','ResourceNb',\n",
    "       'ResourcesMeanEntropy', 'ResourcesMinEntropy', 'ResourcesMaxEntropy',\n",
    "       'VersionInformationSize', 'legitimate'])\n",
    "    #looping through the md5 hash\n",
    "    for row in range(0,70536):\n",
    "\n",
    "        #getting the md5 hash cell\n",
    "        cell=result.loc[row][0]\n",
    "        #using the Virustotal API to lookup the latest report\n",
    "        url = 'https://www.virustotal.com/vtapi/v2/file/report'\n",
    "        params = {'apikey': \n",
    "                  'apikey-value',\n",
    "                  'resource': cell,'allinfo':'true'}\n",
    "        #Using Dicts from Json reponse to info from the report\n",
    "        response = requests.get(url, params=params)\n",
    "        #print(response.json().keys())\n",
    "        #Getting the File submitted name on Virustotal\n",
    "        submittedName = response.json().get('submission_names')\n",
    "        #print(submittedName[0])\n",
    "        #Getting the addtionaal info for sections entropy\n",
    "        additionalinfo = response.json().get('additional_info')\n",
    "        #print(additionalinfo)\n",
    "        #Printing the resources languages counter\n",
    "        #print(additionalinfo.get('pe-resource-langs'))\n",
    "        resourceLang= additionalinfo.get('pe-resource-langs')\n",
    "        #Resource Number list\n",
    "        resourceNumber=[]\n",
    "        if resourceLang!=None:\n",
    "            #Looping through the resource Language Dictionary\n",
    "            for lang in resourceLang:\n",
    "                #print(resourceLang.get(lang))\n",
    "                resourceNumber.append(resourceLang.get(lang))\n",
    "        #printing the dictionary keys for additional info page\n",
    "        #print(additionalinfo.keys())\n",
    "        #Getting the machine information\n",
    "        machine =additionalinfo.get('pe-machine-type')\n",
    "        #Getting the version information size\n",
    "        versionInfosize=additionalinfo.get('exiftool')\n",
    "        #Getting the pe resource detail for resource entropy\n",
    "        peresourcedetail=additionalinfo.get('pe-resource-detail')\n",
    "        #Getting the section detail for section entropy\n",
    "        sections = additionalinfo.get('sections')\n",
    "        #resource,rawsize, virtualsize and section lists to compute max, min and mean\n",
    "        sectionVirtualSize=[]\n",
    "        sectionRawSize=[]\n",
    "        sectionEntropy= []\n",
    "        resourceEntropy= []\n",
    "        versionInfosize=additionalinfo.get('exiftool')\n",
    "        #print(versionInfosize)\n",
    "        #print(type(versionInfosize))\n",
    "        #checking the submittedName list is not empty\n",
    "        if len(submittedName)>0:\n",
    "            name = submittedName[0]\n",
    "        #Checking is the resource info and  section info exists in the report\n",
    "        if (peresourcedetail!=None) and (sections!=None):\n",
    "            #looping through the section list to get the virtualsize at index 2\n",
    "            for virtualsize in sections:\n",
    "                if float(virtualsize[2])!=None:\n",
    "                    sectionVirtualSize.append(float(virtualsize[2]))\n",
    "            #looping through the section list to get the rawsize at index 3\n",
    "            for rawsize in sections:\n",
    "                if float(rawsize[3])!=None:\n",
    "                    sectionRawSize.append(float(rawsize[3]))\n",
    "            #looping through the peresource dict\n",
    "            for resource in peresourcedetail:\n",
    "                #checking if getting resource entropy exists \n",
    "                if resource.get('entropy')!=None:\n",
    "                    resourceEntropy.append(resource.get('entropy'))\n",
    "            #looping through the sections list\n",
    "            for entropy in sections:\n",
    "                #Checking if getting section entropy exists\n",
    "                if float(entropy[4])!=None:\n",
    "                    sectionEntropy.append(float(entropy[4]))\n",
    "        legitimate=0\n",
    "        #checking for a Legitimate files\n",
    "        if response.json().get('positives')>0:\n",
    "            legitimate=0\n",
    "        else:\n",
    "            legitimate=1\n",
    "        #checking for NoneType error on the versionInfosize\n",
    "        if versionInfosize!=None:\n",
    "            versionInfosize= len(versionInfosize.keys())\n",
    "            #checking is the sectionVirtualSize,sectionRawSize,sectionEntropy and resourceEntropy lists are not empty       \n",
    "            if len(sectionVirtualSize)!=0 and len(sectionRawSize)!=0 and len(sectionEntropy)!=0 and len(resourceEntropy)!=0 and len(resourceNumber)!=0:\n",
    "                #Writing the hash,maxresourceEntropy,minresourceEntropy, \n",
    "                #maxsectionEntropy,minsectionEntropy,meansectionEntropy to the dataset\n",
    "                dataset_writer.writerow([name,cell,machine,format((sum(sectionEntropy)/len(sectionEntropy)),\".9f\"),\n",
    "                                         min(sectionEntropy), \n",
    "                                         max(sectionEntropy),format((sum(sectionRawSize)/len(sectionRawSize)),\".9f\")\n",
    "                                         ,min(sectionRawSize), \n",
    "                                         max(sectionRawSize),format((sum(sectionVirtualSize)/len(sectionVirtualSize)),\".9f\")\n",
    "                                         ,min(sectionVirtualSize), \n",
    "                                         max(sectionVirtualSize),sum(resourceNumber),format((sum(resourceEntropy)/len(resourceEntropy)),\".9f\")\n",
    "                                         ,min(resourceEntropy),max(resourceEntropy),versionInfosize,legitimate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
